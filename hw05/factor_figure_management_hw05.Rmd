---
title: "Factor and Figure management"
author: "Santiago David"
date: '2017-10-20'
output: github_document
---

#### Load data and packages
```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(singer))
suppressPackageStartupMessages(library(forcats))
data("singer_locations")
```

# Factor management

### Singer version

####**Objective 1 Factorise**: 

Transform some of the variable in the singer_locations dataframe into factors: pay attention at what levels you introduce and their order. Try and consider the difference between the base R as.factor and the forcats-provided functions

**Process**: We can start checking at the type of variables in `singer_locations`, and confirm that they are not `factors`

```{r}
glimpse(singer_locations)
```

Now, I will save the database in a different object and will mutate `artist_name`, `year`, and `city` from character/integer to factor, but keeping the same variable names...

We can do this using Base R function `as.factor`. 

```{r}
singer_fact <- singer_locations %>% 
  mutate(artist_name = as.factor(artist_name),
         year = as.factor(year),
         city = as.factor(city))
glimpse(singer_fact) # to confirm they are factors now
```

Or we can also use `as_factor` from the package [forcats](https://www.rdocumentation.org/packages/forcats/versions/0.2.0). 

```
singer_forcats <- singer_locations %>% 
  mutate(artist_name = as_factor(artist_name),
        year = as_factor(year), 
        city = as_factor(city))   #gives error
```
However, there are two problems here, the first one is that `year` is an integer in the original database and can't be converted to factor using `as_factor`, and also `city` have NA's, which is giving an error. The solution I considered was to convert year from integer to character first, and then to factor using `as_factor`. Also, we have to specify an entry value for the missing information in city (we explored this in class)...

```{r}
singer_forcats <- singer_locations %>% 
  mutate(artist_name = as_factor(artist_name),
        year = as.character(year),
        year = as_factor(year), 
        city = ifelse(is.na(city), "missing", city),
        city = as_factor(city))

glimpse(singer_forcats)
```

Now, we can see that all three variables are of the type factor, we can also see the difference in the variable `city` between the two methods, since we assigned a new level called "missing" for the NA's, the second example now includes 1317 levels instead of 1316 for the same variable.

```{r}
nlevels(singer_fact$city)
nlevels(singer_forcats$city)
```

####**Objective 2 Drop 0**: 

Filter the singer_locations data to remove observations associated with the uncorrectly inputed year 0. Additionally, remove unused factor levels. Provide concrete information on the data before and after removing these rows and levels; address the number of rows and the levels of the affected factor.

**Process**: We can take advantage of our new database "singer_forcats" with `year` as a factor to try this part. First how many observations were coded as 0, and how many levels do we have in that factor.

```{r}
singer_forcats %>% 
  count(year == 0)
nlevels(singer_forcats$year)
```

We have 100 entries equal to 0 and 10000 for other years plus 70 levels in `year`, so now, I will filter the data for non-zero observations in `year` and save that as a new database. We can inspect the number of observations and levels on this new database:

```{r}
singer_dropzero <- singer_forcats %>% 
  filter(year != "0")

singer_dropzero %>% 
  count(year != 0)
nlevels(singer_dropzero$year)
```

Now, we effectively kept the 10000 observations, but we still have 70 levels!, we need to drop that unused `0` year and other unused levels associated with those observations in `artist_name` and `city`. For this reason it is better to use `droplevels()` from base R.

```{r}
singer_drop_levels <- singer_dropzero %>% 
  droplevels()
```

To understand the effect of removing `year = 0` and `droplevels()`. We can compare the structure of both databases.

```{r}
# before 
str(singer_forcats) 
# after
str(singer_drop_levels) 
```

**observations**: We can see now that there are 100 observations less after removing `year = 0`, but also that the number of levels changed from 7498 to 7408 for `artist_name`, from 70 to 69 for `year` and from 1317 to 1309 for `city` after dropping unused levels.

####**Objective 3 Reorder the levels of year, artist_name or title**: 

Use the forcats package to change the order of the factor levels, based on a principled summary of one of the quantitative variables. Consider experimenting with a summary statistic beyond the most basic choice of the median.

**Process**: Since I have been working with `year` and `artist_name` but not `title`. I will only work with the first two in this section. I have the vague impression that songs were longer between 50's-80's than they are in recent years 90's-00's. So, I will focus in the variable `duration` and specifically in the `mean` duration for all songs per year and `max` duration for each artist.

```{r}
fct_reorder(singer_drop_levels$year,
            singer_drop_levels$duration, fun = mean, .desc = TRUE) %>% 
  levels() %>% 
  head(10)
```

**observation**: I was wrong!, apparently songs were the longest in the 70's, but then also in 2001, 2000 relatively to other years.

We can also explore, which are the artists with the longest songs on average.

```{r}
fct_reorder(singer_drop_levels$artist_name,
            singer_drop_levels$duration, fun = max, .desc = TRUE) %>% 
  levels() %>% 
  head(10)
```
**Observations**: Don't know most of these artists, but they have at least one super long song

####**Extra Objectives (Common part)**: 

- Explore the effects of arrange(). Does merely arranging the data have any effect on, say, a figure?
- Explore the effects of reordering a factor and factor reordering coupled with arrange(). Especially, what effect does this have on a figure?

**Process**: We can use the previous examples. First for average song `duration` and `year`. We start by creating a subset of this data. Only for 20 years, so that we can easily see the effect in figures...

```{r}
singer_subset <- singer_drop_levels %>% 
  group_by(year) %>% 
  summarise(mean_duration = mean(duration)) %>% 
  head(20)
```

We can use `arrange()` on the factor `year` and check if there is any effect in the plot. 

```{r}
arrange(singer_subset, mean_duration) %>% 
  ggplot(aes(mean_duration, year)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

**Observations**: In the previous plot we can see that although we used `arrange()` to sort `mean_duration` by year in descending order, R still keeps the arbitrary order of levels, so that the trend is not really evident.

Now we can try reordering the factor with `fct_reorder` and do the same plot.

```{r}
ggplot(singer_subset, (aes(x = mean_duration, y = fct_reorder(year, mean_duration)))) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

**Observations**: Now, in this plot we can clearly see which years have on average a long song duration, and which ones a shorter one, since they are reorder based on the quantitative variable.

Also, If we use `arrange()` and `fct_reorder`, we have the same effect than just using `fct_reorder`

```{r}
arrange(singer_subset, mean_duration) %>% 
ggplot(aes(x = mean_duration, y = fct_reorder(year, mean_duration))) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# File I/O

**Objective**: 

- Experiment with one or more of `write_csv()/read_csv()`, `saveRDS()/readRDS()`
- Create something new, probably by filtering or grouped-summarization of Singer or Gapminder
- Fiddle with factor levels, and Explore whether this survives the round trip of writing to file then reading back in.

**Process**: I start by creating a new summary from `singer` to write in and out in this part of the homework. I don't remember what `artist_hotttnesss` mean, but I guess it is some sort of popularity measurement, so let's try to get then mean `artist_hotttnesss` across years for each artist. I will use `singer_forcats`, since I already coded artist_name and year as factors in that database.

```{r}
artist_hotness <- singer_forcats %>% 
  group_by(artist_name) %>% 
  summarise(mean_hotness = mean(artist_hotttnesss))
str(artist_hotness)
head(artist_hotness)
```

I will use `write_csv` and `read_csv` to get this subset of data in and out of r...
```{r}
write_csv(artist_hotness, "artist_hotness.csv")

# now read them back
artist_hotness <- read_csv("artist_hotness.csv") %>% 
  mutate(artist_name = as_factor(artist_name)) # creating factor
glimpse(artist_hotness)
```

The file was indeed exported and imported without major issues. However, `artist_name` was imported as a character variable instead of a factor... Let's mutate that again, and check the order of levels in this file

```{r}
head(levels(artist_hotness$artist_name))
```

This order doesn't seem to follow any particular rule, it is just the first artist names entered in the original database. I will reorder the `artist_name` factor levels according to mean hotness in decreasing order.

```{r}
artist_hotness <- artist_hotness %>% 
  mutate(artist_name = fct_reorder(artist_name, mean_hotness, .desc = TRUE))
head(levels(artist_hotness$artist_name))
```

Alrigth, so now we know that Daft Punk, Black Eyes Peas, and Coldplay, are the artists with the highest mean hotness index, and also our levels are organized that way... I will export this again using `write_csv` and `saveRDS()` and read them back...

```{r}
write_csv(artist_hotness, "artist_hotness.csv")
saveRDS(artist_hotness, "artist_hotness.rds")

# Now read them back
artist_via_csv <- read_csv("artist_hotness.csv") %>% 
  mutate(artist_name = as_factor(artist_name)) # with factor
artist_via_rds <- readRDS("artist_hotness.rds")
```

Lets take a look again at the order of levels for these two files

```{r}
head(levels(artist_via_csv$artist_name))
head(levels(artist_via_rds$artist_name))
```

**Observations**: The first route, using `write_csv` and `read_csv` didn't conserve the reorder we computed based on mean hotness, but the second option using `saveRDS()` and `readRDS()` did it. I had to read and google what the .rds file was, since I have never use it. I also got a lot of help from the materials of this class for last year.

# Visualization design

**Objective**: 

Remake at least one figure or create a new one, in light of something you learned in the recent class meetings about visualization design and color. Maybe juxtapose your first attempt and what you obtained after some time spent working on it. Reflect on the differences.

```{r}

```



# Writing figures to file

# Clean up your repo!


